## 딥러닝

12주 수업으로 진행

Keras 사용해서 딥러닝을 구현해볼 예정

- 다른 플랫폼도 많지만 Keras가 쉽기 때문에 이렇게 진행



---

## 1. 인공지능과 머신러닝, 딥러닝

명확한 경계를 잘 파악할 필요가 있음

인공지능하면 막연한 개념으로 쓰이고있다.

딥러닝은 사실 사람들의 인지과정과 다소비슷하다. 그래서 문제를 해결할때 가장 중요한건 문제를 어떻게 바라보고 접근할 것 인가가 된다. 컴퓨터가 모든걸 다 한다고 생각할게 아니다. 사람의 직관이 들어가야하는 것이다. 그래서 내가 만약 이걸 구분한다면 어떻게 구분할것인가 하는것에 대한 생각을 가지고 들어가야한다. 

- 컴퓨터에게 가이드라인을 사람이 줘야한다. (손실함수 or 목적함수) 그리고 이게 Make sense 해야한다. 내가 나누는 기준을 컴퓨터가 따라오도록 해야한다.

-> 사람이 분류하는 기준이 어느정도 대입이 되어야 사람만큼이라도 분류할 수 있다.



#### 머신러닝

- 샘플과 기댓값이 주어졌을 때 데이터 처리작업을 위한 실행규칙을 찾는 것 이다.
  - 기댓값 -> label
  - 데이터와 해답을 동시에 줌으로써 규칙을 찾아냄
- 명시적 프로그램이 아니고, 훈련되는 프로그램이다.
- 어떤 작업을 자동화하기위한 규칙을 만들어낸다.

- 실천적인 접근방식 때문에 이론보다는 경험을 바탕으로 아이디어가 증명되는 경우가 많음

  - 여기서 이렇게해보고 저기서 이렇게 해보고 결과를 바탕으로
  - 실제로는 부딛혀봐야 한다는 말이다.

  - 기본적으로는 영상처리를 잘 배워서(전통적인 방법)  했으면 좋겠음
    - 딥러닝에서 문제점이 생기면 영상을 다뤄본 경험들이 도움이 많이 될 것이기 때문이다.



> 딥러닝은 데이터에서 표현을 학습하는 것 이다.

데이터를 입력으로 쓰고, 해답을 기대출력으로 볼 때, 데이터를 적절한 표현방식으로 변환하는걸 학습이라고 볼 수 있다. 특징적인걸 비교할 수 있도록 만들어야하는데, 그 특징을 숫자로 표현할 수 있어야한다. 특징적인 부분에 대한 값을 하나의 다른축으로 형성을 해서 구분을 하는 축으로 바꿔주는 것 이다. (사진으로 되어있는걸 구분하기 쉬운 함수적 축으로 바뀌게 되는 것 이다.)

머신러닝과 딥러닝의 핵심문제는 의미있는 데이터로의 변환이다.

머신러닝 모델은 입력 데이터를 의미있는 출력으로 변환한다.

데이터를 가지고 내가 원하는 표현방향으로 바꿔주는 변환프로그램을 만든다라고 생각하자.

encording -> 숫자로 변환해주는것

표현의 핵심은 데이터를 인코딩하거나 묘사하기 위해 데이터를 바라보는 다른 방법이다.

어떤 한문제에 대해서도 여러가지 컴퓨터가 어떻게 접근할지는 돌려봐야알게 될텐데, 더 나은 표현으로 데이터를 미리 변경하는 방법도 있다. translation, rotation 시키면 중심축을 기준으로 데이터를 퍼트릴 수 있다.

![image-20200903095143121](C:\Users\jungse\AppData\Roaming\Typora\typora-user-images\image-20200903095143121.png)

분류하기 쉽게 데이터를 바꿔나간다. (데이터의 더 나은 표현)



#### 딥러닝에서 '딥'이란 무엇일까?

- 연속된 층으로 이루어져있다.

  - 층들을 거쳐가면서 유용한 표현으로 변환된다.

  - 1~2층으로 된건 머신러닝으로 분류

    - 딥러닝은 많게는 천개까지도, 그만큼많이 쌓아올린다. 데이터가 호락호락하지 않기 때문에 그렇다.

    - 복잡한 데이터가 층을 거치면서 모양이 변하면서 "더 나은 표현"이 되는 것 이다.

- 원래 딥러닝이 뇌구조를 이해하는것부터 영감을 얻어 개발한건 있지만, 뇌를 모델링한건 아님
  - 최근에는 여러개의 Network를 연결해서 그렇게 만들어보려는 과정도 있음
- 우리가 다루는 딥러닝은 그냥 데이터로부터 표현을 학습하는 수학 모델일 뿐임
  - 별거아니고, 그렇게 신비롭지도 안하는걸 인지해라
  - 만만하다 만만해

ex) MNIST로 숫자구분 프로그램은 데이터를 어떻게 변환할까요?

내가 모델에게 줄 데이터는 입력과 진짜 출력

내가 준 입력이 4개의 출력으로 처음으로 변환이 된다. 또다시 이것들의 조합에 의해서 4개의 다른표현으로 바뀌고, 이게 또 입력이 되서 또 다른표현으로 바뀌고, 4개였던게 하나로 합쳐져서 나오게 되는데, 이때 이게 숫자를 판별하는 데이터가 되서 나오게 되는 것 이다.

정보가 연속된 필터를 통과하면서 순도높게 정제되는 다단계 정보추출 작업이라고 생각할 수 있겠다. 지금보니까 픽셀사이즈도 점점 커진다. 픽셀들이 압축이 되서 중요한 정보를 가지게 되고, 표현방식이 필터를 거치면서 단순해졌다. 표현하기 쉬운 축으로 매핑을 시켜준다! 가만보면 한 층 안에 필터가 여러개가 있다. 각각의 필터가 하나의 최초 입력으로부터 내가 뽑고싶은 특징을 추출한다.



#### 딥러닝의 작동원리 이해하기

![image-20200903101223059](C:\Users\jungse\AppData\Roaming\Typora\typora-user-images\image-20200903101223059.png)

![image-20200903101742185](C:\Users\jungse\AppData\Roaming\Typora\typora-user-images\image-20200903101742185.png)

![image-20200903101950012](C:\Users\jungse\AppData\Roaming\Typora\typora-user-images\image-20200903101950012.png)

- 입력데이터, 기대출력 값이 있고, 중간에 데이터를 변환시키는 층(신경망 모델)을 만들어준다. 이 부분을 개발자가 설계를 한다.

- 가중치는 중간에서 어떤 component를 더 중요하게 반영할 것인가 하는 것에 대한 것
  - 가중치에 따라서 filter의 특성이 바뀌게 된다.
- 원하는 데이터로 입력을 변환하기 위한 가중치를 찾아내는게 Training
  - 학습은 주어진 입력을 정확한 타깃에 매핑하기 위한 신경망의 모든 층에 있는 가중치 값을 찾는 것을 의미한다.
- 손실함수는 원하는 파라미터(가중치)를 찾는 가이드라인이다.

- 원하는 가중치로 값을 얻기 위해서 손실함수를 통해, 내가 원하는 값하고 얼마나 가까워지는지를 볼 수 있다. (y -y')
- 가중치값을 수정해주는게 optimizer -> 손실함수가 0에 가까워지도록

순서

1. 입력데이터와 타깃 설정
2. Layer 구성 (모델형성)
3. 손실함수 정의
4. Optimizer 선정

나중에는 손실값을 손실점수로 바꿔서 그래프에 표현할 수 있다.

첫 가중치는 랜덤값이다.

loss의 추세를보고 학습이 잘 되고있는지 안됐는지 잘 확인해야한다.



## 딥러닝 이전: 머신러닝의 간략한 역사

#### 확률적 모델링

- 통계학적 이론을 데이터분석에 응용한게 머신러닝의 시작이 됨

-> 나이브 베이즈 알고리즘

- 확률적 모델을 통해 classification함
- 테니스 예시

-> 로지스틱 회귀

- 분류 알고리즘이다. 이름은 회귀지만

####  초창기 신경망

- 역전파 알고리즘 재발견으로 매우 빠르게 발전함 (경사하강법 최적화 사용)
- LeNet : 성공적인 첫번째 신경망
  - 벨 연구소에서 개발, CNN 적용, 역전파 알고리즘과 결합
  - 손글씨 숫자 이미지를 분류하는 문제에 적용
  - 우편봉투의 우편번호 코드를 자동으로 읽기위해 사용한다.

- 커널방법 : SVM
  - 벨 연구소에서 개발
  - 딥러닝이전 가장 인기있던 알고리즘
  - 커널함수를 사용해서 데이터 형태를 바꿔준다.
    - 딥러닝에서는 커널함수의 역할을 Layer가 해준다.
  - 커널함수는 데이터로부터 학습되지않고 직접 정해줘야한다.
  - 분할 초평면은 학습을 통해 찾아낸다.
  - Feature engineering을 통해 커널을 디자인한다. (유용한 표현 추출)

#### 결정트리, 랜덤 포레스트, 그래디언트 부스팅 머신

등등등



#### 다시 신경망으로

2010년대 다시 신경망은 성과를 내기 시작한다.

하드웨어의 발전과 인터넷이 발전, DB를 만들어낼수있는 포털사이트가 발전하고 데이터의 수가 많아지면서 발전이 이루어졌다.

#### 머신러닝 기법의 한계

학습이 얕아서 입력데이터가 복잡하면 처리를 못한다. 간단한 것만 가능하고, 좋은 표현을 사람이 초기 입력 데이터를 수동으로 변환해야한다. (DATA PREPROCESSING)

#### 딥러닝의 특징

- 특성공학단계를 완전 자동화했다.
- 각각의 표현층 파라미터의 변화가 순차적이 아니라 공동으로 이루어진다.

- 층을 거치면서 점진적으로 더 복잡한 표현이 만들어지고 ,점진적인 중간 표현이 공동으로 학습된다.
- 각 층은 상위,하위 층에 따라 같이 바뀐다.
- 일반적으로 Classification, detection같은 지각관련문제에 많이 사용됨



## 3. 왜 딥러닝일까? 왜 지금일까?

- 하드웨어의 발전
  - GPU 병렬연산
  - TPU도 있음
- 데이터셋의 증가
  - 데이터는 머신러닝의 연료, 대량의 데이터가 수집됨
- 알고리즘 향상
  - 매우 깊은 신경망을 훈련시킬수 있는 안정적인 방법을 못찾았었음
    - 그래디언트를 전파하기 어려웠다.
    - 층이 늘어남에 따라 앞쪽 피드백이 희미해졌었다.
  - Activation function의 등장
    - non-linearity를 만들어줘서 불필요한 값 제거
  - Weight initialization
  - Optimizer
  - Batch normalization
  - residual connection
  - depthwise separable convolution

이 세가지가 머신러닝 발전의 재료

cuda로 신경망 구현하는법 [http://www.yes24.com/Product/Goods/44202771](http://www.yes24.com/Product/Goods/44202771)

투자도 엄청많이 되서 시장이 엄청 커졌다.

도구들의 대중화도 한몫함

- theano, tensorflow, keras

그래서 우리는 좀더 전문성을 키워야할 필요가 있다. 좀더 Low level로..



## 딥러닝을 위한 기초 수학

내가 원하는 대로 변환시켜주는게 바로 식(표현)인 것이다. 그래서 수학적 모델은 항상 일차식으로 시작함 y = wx + b

이차식은 Loss 함수에서 많이 나옴, 최솟값을 찾아내는 과정이 중요함

loss = y - y' 인데 gradient descent 방법을 쓰기위해서 제곱식으로 해서 사용한다.

(y-y')^2에서 y은 정답이니까 상수고 y' = wx+ b 니까 (y-wx)^2인데 사실 b도 w에 포함이됨. 그래서 (y-wx)^2 형태가 되는데, 이때 x축이 w, y가 loss로 바뀌게 된다.

loss = (y-wx)^2

미분계수는 기울기를 뜻한다.

왜 편미분개념은 왜나오지?

loss로 돌아가서, w에 대한 식으로 바뀌게 되는게 있었다.

네트웍을 거쳐서 나온 y'은 wx로 근사화를 할 수가 있음

근데 보면 w은 엄청많잖아. 그래서 loss function은 사실 2차원이 아니라 다차원이다. 일단 단순하게 생각해서 그래프로 표현을 하지만, 실제로는 n차원이라는것

그러다보니까 2차원으로 보고 표현하기 위해서 편미분이 필요한 것 이다.

w1에 대해서 편미분하면 w1에 대한 loss가 나오고, w2에 대해 편미분하면 w2에 대한 loss가 나오고/./.

시그모이드는 앞으로 자주 볼 함수

근사화시켜서 사용하곤 함 1/ 1+e^(-(ax+b)) 처럼 식이 변경되서

a가 커지면 급격히 올라가고 줄어들고, a가 작으면 더 완만해짐, b는 수평이동을 뜻함

왜 이렇게할까요?

y' = wx _+ b 형태로 나온다고 했죠? 이 레이어를 거쳐서 나온 출력이 다음 activation function의 x가 되는것이죠

그러면 입력값이 activation함수를 거치면서 어떤건 0, 어떤건 1이되는데 w와 b에 의해ㅓ 이 함수의 모양이 바뀌게 되는것이지



그리고 시ㅏ그모이드 함수에서 처럼 우리가 관심있는건 0~1사이 모습임 그래서 대칭시키고 평행이동시키면서 0과 1사이로 그래프를 옮김

![image-20200903121223326](C:\Users\jungse\AppData\Roaming\Typora\typora-user-images\image-20200903121223326.png)



## 신경망을 위한 데이터 표현

- Tensor: 다차원 넘파이 배열
  - 데이터를 위한 컨테이너
- 대부분의 머신러닝 시스템은 tensor를 기본 데이터구조로 사용한다.
- 차원에 따라서 종류가 여러개로 나뉨
  - 스칼라: 값 하나만 가지고 있는 tensor (0D tensor) b
    - 상수의 개념이라고 보면 될 것 같다.
  - 벡터 : 1D 텐서x
    - 원소의 개수가 사이즈(rank??)
  - 행렬 : 2D 텐서xxx
  - 텐서 : 3D 텐서 xxxxxx

![image-20200903130904427](C:\Users\jungse\AppData\Roaming\Typora\typora-user-images\image-20200903130904427.png)

**데이터를 loading하면 size, 축의 개수, 타입확인이 꼭 필요하다.**





텐서

![image-20200903132416460](C:\Users\jungse\AppData\Roaming\Typora\typora-user-images\image-20200903132416460.png)

굵은글씨 앞뒤에 애들이 붙는게 보이지

EEG라고 할떄 전극이 여러개있으면 그게 feature의 개수가 됨

케라스에서 들어가는 데이터의 순서~



## 신경망의 톱니바퀴: 텐서연산

#### 브로드캐스팅

보통은 크기가 같아야 연산이 가능하지만

크기가 다를경우 **브로드캐스팅**이라고해서, 원소별 연산은 몬하니까 옆에 얘를 하나하나 옆으로 이동시켜가며 더해주게됨 (forloop)으로 한 열씩 더해주는 느낌으로 전달, 전파한다.



#### inner product (dot product)

두개의 벡터가 있을때, 원소별 곱을 하고, 전부 더해서 하나의 값으로 만들어내는 것 이다.

근데 벡터가 아니라, 행렬간의 dot product를 하면 결과는 matrix가 나온다.



#### Tensor reshaping

shape을 변경했을때, 그 수는 똑같아야한다.

 ex) 300 20 -> 20 300 -> 15 * 400

transpose는 행과 열을 바꾸는 것 이다.

A가 B와 더해짐으로써 C라는 위치로 위치가 바뀐다는 것이다. 

덧셈은 평행이동을 뜻하고, 곱셈은 회전을 나타낸다.

나타내고싶은건, 결국 기하학적 이동을 할 수 있다는건데, 딥러닝에서 Layer를 거친다는게 좀더 의미있는 형태로 변화시켜가는건데, 이게 결국 기하학적 변환을 매우 복잡한 기하학적 변환을 한다는것으로 해석할 수 있다.

affine transformation??

두개의 종이로 뭉쳐진 종이공을 레이어를 거치면서 분해하는 과정인데, 잘 분해하려면 데이터가 정말정말 많아야한다.

