# 딥러닝 8주차

## 오토인코더 (AutoEncoder)

머신러닝에서 어떻게 딥러닝으로 확장이 되었나에 대해

- 머신러닝에서 차원을 줄이는 여러가지 기법들이 있는데 (예시로 PCA, 보통 선형을 가지게 됨), Autoencoder의 다른점은 비선형을 가지게 된다. 

Unsupervised learning 기법을 사용한다.

label없이 학습을 하긴하지만 100% 비지도 학습은 아니다. 자기 자신으로 돌아가는 과정을 통해서 특성을 추출해가는 것이 Autoencoder

사실 자기 자신으로 돌아가는건 아무것도 안해도 되는거긴 하지만 그 사이에 비밀이 있다.

- 첫번째 비밀은 구조에 있다.
  - 영상의 사이즈를 일부러 줄여줌으로써 원래 자기자신의 Form을 갖지 못하게 만든다.
    - 일부러 압축시켰다가 다시 복원하도록 만든다.

 ex) 128 128 짜리를 10개로 압축시킨다. 이때 10개로 압축되는 과정에서 128개 중에서 중요한 정보들만 모아 줄이고, 그 정보로 부터 원래 자기 자신으로 복원시키는 과정을 학습을 시킨다.

자기 자신의 입력을 원래대로 재현시키는 과정을 Encoding / decoding 과정이라고 하는데, 이 과정을 통해서 입력데이터에서 중요한 특성을 얻어낼 수 있다.

물론 차원이 축소됨으로써 생기는 문제가 있다고는 하지만 (손실이 발생), 최근에는 해결방법이 생겨나고있다.

현재 많은 네트워크에서 활용이 되고 있는데, U-Net, GEN에서도 활용되고 있다.

압축공간에서의 사이즈를 어떻게 잡느냐에 따라서 얼마나 다시 돌아갈 수 있는지 정해진다.

- 압축되는 정보의 양을 잘 설정해야한다. (손실을 줄이기 위해서)
- 요즘 U-Net같은 경우는 옆에서 concatenation을 시켜주는 connection이 존재하기 때문에 decoding할 때 같이 넣어서 복원을 하기 때문에 손실이 있으면 안되는 영상처리를 하는경우 이런 방식을 사용해야한다.

앞부분인 Encoder 부분은 특성추출 과정이 된다.

- 압축시킨뒤 다시 자기 자신으로 돌아갈 때 사용되는 특징이 되는 공간을 만든다.

- 비지도 학습이지만 자기자신으로 돌아간다는것이 

#### 오토인코더 장기

Denoising과 차원 축소를 엄청잘한다.

- Denoising: 잡음제거
  - 노이즈만 싹 제거 가능
  - 중요한 정보만 압축했다가 원본이미지로 재현을 하는건데, 노이즈는 중요한 정보로 취급되지가 않나봄
  - Low pass filtering이 구조적으로 된다.

퍼즐맞추기도 잘한다.

#### 구성요소

- 인코딩
  - 입력되는 데이터를 저차원 압축공간으로 encoding
- 디코딩
  - latent vector를 원본입력으로 복원

#### 특징

- Data specific: 훈련데이터와 비슷한 데이터로만 압축된다.
  - 훈련한 데이터에 대해서만 좋은 성능을 낸다.
- 손실압축
- 자동학습



#### Latent vector

압축된 정보를 가지고 복원을 할 때, 특성을 만들어줄 수 있는 잠재 Vector다. 

각각의 축들이 어떤 특성에 대한 정보이기 때문에 이것들을 합성해서 가지고있지 않은 정보도 만들어낼 수 있는 잠재력을 가지게 된다.

#### Encoding

특성을 추출해내는 부분이다 보니까, Pre-trained된 걸 사용해도 된다. 훨씬 좋은 성능을 얻을 수 있을 것이다.



RGB에서 LAB로 바꾸고

입력은 L, 출력은 AB

L이 들어가면 AB가 나오도록

나온 출력과 입력을 합친다음 RGB로 다시 변환한 뒤에 출력

L 데이터만 넣어주면 AB가 나오도록 만들기