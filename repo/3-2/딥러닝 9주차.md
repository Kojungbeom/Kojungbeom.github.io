# 딥러닝 9주차

## U-Net

오토인코더와 비슷한 구조로 되어있다.

하지만 가장 큰 차이점은 옆에서 바로 연결되는 (Copy and crop) 기법이 사용된다.

-  Concatenatation

왼쪽에서 압축된 Feature가 밑에서 올라온 Feature와 합쳐지게 된다.

오토인코더의 문제점은 압축하고 다시 Decoding하는 과정에서 Blurring되는 현상이 있었다. (손실이 존재한다.)

하지만 U-Net에서는 왼쪽에서(해상도가 높은쪽에서) 중간중간 중요한 Feature가 합쳐지기 때문에 손실을 최소화 할 수 있다. 

- 좌상단쪽 레이어에서는 초기 레이어이기 때문에 보통 Edge정보를 가지고 있다.
  - Edge에 대한 정보손실이 최소화되기 때문에 Blurring이 적다.

영상처리를 한다고하면 U-Net은 Standard가 되고 많이 쓰이는 모델이니 잘 알아두어야한다.

- 입력과 출력이 같은 해상도를 가지는 문제에 대해서 사용할 수 있다.

Autoencoder와의 차이점에 대해 인식하고 중간중간 건너오는 Feature가 어떤건지 생각해봐야한다.



#### Transposed Convolution

기존의 Convolution과 반대다. dot product를 통해 커널내의 값을 가지고 연산을 해 하나의 점을 만드는것을 채널수에 따라 반복하여 만들어가는게 Convolution이었다고 하면, Transposed convolution은 반대로 입력 영상이 있고 3x3 kernel이 있다고 할 때, dot product와 반대로 kernel의 weight의 값이 곱해져서 하나의 값이 kernel속 pixel의 개수만큼으로 만든다.

- dot product -> 3x3을 하나의 점으로 매핑
- 반대 -> 하나의 점을 3x3 or other size로 매핑
  - Up convolution도 마찬가지로 동작한다.
  - Stride를 써서 옆으로 하나씩 척척붙이다보니 영상이 커진다.
  - 입력의 dimension보다 2배 커지도록해서 사용한다.
    - Stride를 쓰지않으면 사이즈를 똑같이 할 수 있지만 그런짓은 잘 안한다.

이런식이 아니라 원래하던것처럼 Convolution을 하고 Upsampling? U

모르겠다.

Keras에 Transposed convolution을 사용할 때는 strides=2, kernel_size는 (2,2)를 많이 사용한다.



U-Net의 경우에는 구조적으로 Convolution과 Transposed convolution이 대칭적으로 일어난다.

거기에 추가적으로 Concatenation이 일어나고 있다는걸 기억하자.

keras에는 Concatenate라는 function도 지원을 하니까 이걸 사용하자.

((f1, f2), feature 방향으로)



# 회사에서 프로젝트 어떻게 하는지

- 자체개발
- SI(System Integration) or 과제

## 

트롤리, 슬랙, 



데이터 하나 골라서 

딥파이로 할 사람 딥파이로 하고, 코드 짤사람 코드로 해서 학습시켜서 성능내서 보고서 형태로 만든다음 제출하면 된다.

- 워드에다가 자유롭게 작성하려고했는데 양식 달라해서 양식에다가 해야함



1. 클래스 늘려서 해보기?

선택한 데이터셋에 대한 이해, 네트워크에 대한 이해, **설명**